% Introduction to SNR optimisation in PyCBC Live
The PyCBC Live search pipeline identifies \gwadj signals in real-time from the \gwadj data provided by the current international \gwadj network. Sky maps are produced of the found \gwadj events, which indicate the sky position of the source of the signal. The sky localisation is more accurate for an event with a greater signal-to-noise ratio (SNR), therefore, as part of the pipeline we rapidly optimise event SNR using an optimisation algorithm to recover the greatest SNR and more accurate sky localisation possible.

There are many optimisation algorithms with many tuneable hyperparameters which determine operating parameters of the algorithm, the appropriate algorithms and hyperparameter values need to be chosen to ensure the optimisation performs optimally. The optimal methods for optimising SNR in PyCBC Live were researched and improved multiple times across the course of the PhD. These changes are being written up in the PyCBC Live fourth observing run methods paper.

\section{\label{7:sec:introduction}Introduction}

% % Background and Context
% Big Picture: Start by placing the topic in a broader scientific or academic context. Why is this field of study important?
% Specific Focus: Narrow down to the specific problem or area your paper/chapter will address.

As described in chapters~\ref{chapter:5-pycbc-live} and~\ref{chapter:6-earlywarning} the PyCBC Live search pipeline (among others) is responsible for detecting and producing accurate sky maps of \gwadj signals in low-latency. Search pipeline events are uploaded to the Gravitational-Wave Candidate Event Database~\cite{ligo_gracedb:2024} (GraceDB) from which a \textit{preferred event} is chosen to send a GCN Circular~\cite{gcn_circulars:2024} (a rapid astronomical bulletin submitted by and distributed to astronomy community members worldwide). The preferred event is chosen based on a listed selection criterion. These rules are taken verbatim from~\cite{gracedb_superevent_selection}:

When multiple online searches report events at the same time, the preferred event is decided by applying the following rules, in order:
%
\begin{itemize}
    \item A publishable event, meeting the public alert threshold, is given preference over one that does not meet the threshold.
    \item An event from CBC searches is preferred over an event from unmodeled Burst searches (see Searches for details on search pipelines).
    \item In the case of multiple CBC events, three-interferometer events are preferred over two-interferometer events, and two-interferometer events are preferred over single-interferometer events.
    \item In the case of multiple CBC events with the same number of participating interferometers, the event with the highest SNR is preferred. The SNR is used to select the preferred event among CBC candidates because higher SNR implies better sky location and parameter estimates from low-latency searches. In the case of multiple burst events, the event with the lowest FAR is preferred.
\end{itemize}
%
The PyCBC Live search is a CBC search and when analysing the same number of interferometers as other CBC searches there is a tie-breaker for preferred event dependent on the SNR of the event.

% 2. Motivation and Relevance
% Why This Topic?: Explain why the topic of your paper or chapter matters. What are the practical, scientific, or theoretical reasons that make it worth investigating?
% Gap in Knowledge: Identify any gaps or unresolved issues in the current literature that your work will address.
It is clear from these set of rules that to become the preferred event with the most accurate sky map, we must upload the event with the highest SNR. This is where the PyCBC Live SNR optimiser becomes relevant. We construct our template bank with a minimum match of $0.97$, allowing up to a $3\%$ SNR loss for any event. If we want to maximise the SNR of our event, we must perform a finer search over the template bank parameter space around the initially found template to recover that potentially lost $3\%$.

% 3. Objectives and Research Questions
% Main Goals: Clearly state the primary objectives of the chapter or paper. What do you aim to achieve or contribute?
% Research Questions: If applicable, list specific research questions or hypotheses that guide your work.
The SNR optimiser uses optimisation algorithms which tune input parameters (template parameters) to maximise (or minimise) an output (network SNR). There are a number of different optimisation algorithms operating under different mathematical optimisation techniques, all of which have hyperparameters which can be tuned to the problem space to optimise optimiser performance---both output value and computational time.

We detail the investigation into an optimal optimisation algorithm for PyCBC Live along with the tuning of the hyperparameters for this optimisation algorithm, how these algorithms were tested and the results of using the SNR optimiser on a number of PyCBC Live events.




% Goals: State what you aim to cover in this chapter (history, methods, results, and implementation).

In Section~\ref{7:sec:optimising_snr_in_low_latency} we discuss how the SNR optimiser fits into the PyCBC Live search pipeline and when it is run, alongside this we detail the generic form of the optimisation algorithms and the current optimiser being used in PyCBC Live. In Section~\ref{7:sec:original_bounds} we list the parameter value bounds for the optimised parameters and how these were calculated, in Section~\ref{7:sec:original_de} we detail the \textit{differential evolution} optimisation algorithm and in Section~\ref{7:sec:de_hyperparameter_tuning} how the hyperparameter of this algorithm were tuned and the improvements from tuning the hyperparameter. In Section~\ref{7:sec:exploring_alt_opts} we explore other optimisers and describe Particle Swarm Optimisation, the newly implemented optimisation algorithm. We detail some additional improvements to the SNR optimiser in Section~\ref{7:sec:additional-improvements} and in Section~\ref{7:sec:results} we analyse the average SNR increase of the SNR optimiser over the events uploaded by PyCBC in 2024. We conclude in Section~\ref{7:sec:conclusion} and detail potential future improvements to the SNR optimiser.

\section{\label{7:sec:optimising_snr_in_low_latency}Optimising SNR in low-latency}

The PyCBC Live search will matched filter the entire template bank with the data ring buffer every analysis stride (see chapter~\ref{chapter:5-pycbc-live} for greater detail). The matched filter will produce SNR triggers when any template has been found with a matched filter above an SNR of $4.5$. The PyCBC Live search will then pass these triggers to the ranking statistic, taking into account any signal-consistency test values or other ranking statistic components, to find the most significant coincident set of triggers. After the uploading of an event to GraceDB, the PyCBC Live search will spawn a subprocess and the PyCBC programme \texttt{pycbc\_optimize\_snr} is initialised. This programme takes the \gwadj data and is given the event template parameters to run a finer search over the parameter space, specifically optimising for the network SNR. This finer search is performed not using a template bank approach but with an optimisation function, a process that finds the `best' possible solution by maximising for a particular objective given input parameters that can be tuned. For PyCBC Live the objective being maximised is the network SNR and the tuneable input parameters are the template bank parameters: primary component mass $m_{1}$, secondary component mass $m_{2}$, primary spin z-component $s_{1z}$ and, secondary spin z-component $s_{2z}$. Boundaries are applied to the input parameters, which are calculated using the initial event parameter values.

We run this SNR optimisation to produce better sky maps for the GraceDB `super event' (the \gwadj signal each pipeline event has observed). An example for a recent \gwadj signal (S240924a~\cite{superevent_S240924a}) can be seen in Figure~\ref{7:fig:gracedb_pref_event}.
%
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/7_snr_optimiser/gracedb_public_snr_optimiser.png}
    \caption{The public webpage for the superevent \gwadj signal observed on the 24$^{\text{th}}$ September 2024, S240924a~\cite{superevent_S240924a}. The preferred search pipeline for this event can be seen in the table titled `Event Information', where it can be seen that a PyCBC Live is the preferred event.}
    \label{7:fig:gracedb_pref_event}
\end{figure}
%
When all pipelines pass the public alert threshold and use the same number of interferometers, the tie for preferred event is broken by the SNR of the event. For S240924a, we can see the PyCBC event (which was the preferred event) was an SNR optimised event, indicated by the label `SNR\_OPTIMIZED' in Figure~\ref{7:fig:gracedb_snr_optimizer}.
%
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/7_snr_optimiser/gracedb_pycbc_pref_event.png}
    \caption{The preferred event for the super event S240924a~\cite{superevent_S240924a} identified by the PyCBC Live search pipeline (among others). This PyCBC Live event was created by the SNR optimiser.}
    \label{7:fig:gracedb_snr_optimizer}
\end{figure}
%

The original PyCBC SNR optimiser was introduced during the second half of the third observing run to improve the sky maps that are generated by PyCBC Live using the SciPy~\cite{SciPy:2020} optimiser \texttt{differential evolution}~\cite{DE:1997}. Examples noted in the original GitHub pull request~\cite{pycbc_pull_request_2659} see increases in network SNR from $9.818$ to $10.149$, an increase of $3.6\%$.

Optimisation algorithms can generally be categorised into two main types based on their approach to searching the parameter space: population-based algorithms and single-solution algorithms. Population-based algorithms initialise a set of candidate solutions (a population) and explore the parameters space iteratively using interactions between the candidates to locate the optimal solution. Single-solution algorithms use a single candidate point that is iteratively improved based on some criteria. Only population-based algorithms have been considered for the PyCBC Live SNR optimiser for their computational efficiency in parallelised computing environments where the network SNR of each point can be computed in parallel using a large number of computing cores. These population-based algorithms all follow the same general steps in optimisation.
%
\begin{enumerate}
    \item Initialise a population of size $N$ with random parameter values
    \item Evaluate the network SNR of the point
    \item Adjust each point in the population using the base optimisation algorithm
    \item Re-evaluate the network SNR of each point
    \item Keep points with greater network SNR
    \item Repeat until the number of max iterations has been reacher \textbf{OR} the population has converged on a point
    \item Output the optimised template solution
\end{enumerate}
%
These instructions can vary slightly for optimisation algorithms and we will explore these differences as well as the point adjusting algorithms in the following sections.

\subsection{\label{7:sec:original_bounds}Parameter bounds}

The optimiser will be passed the template parameters of the event that triggers the SNR optimisation. From these parameters, the \textit{bounds} are defined. These bounds represent the minimum or maximum value that the optimiser can explore for a specific parameter, preventing it from searching areas we do not want it to search.

The mass parameter bounds are created by converting $m_{1}$ and $m_{2}$ into chirp mass, $\mathcal{M}$, and symmetric mass ratio, $\eta$; this combination leads to a more physically meaningful difference in waveform when changed. The $\mathcal{M}$ bounds are calculated,
%
\begin{align}
    \mathcal{M}_{\min} &= 
    \begin{cases}
        \mathcal{M} \cdot \left(1 - \frac{\mathcal{M}}{50.0}\right) & \text{if } \mathcal{M} \cdot \left(1 - \frac{\mathcal{M}}{50.0}\right) \geq 1 \\
        1 & \text{if } \mathcal{M} \cdot \left(1 - \frac{\mathcal{M}}{50.0}\right) < 1
    \end{cases} \\
    \mathcal{M}_{\max} &= 
    \begin{cases}
        \mathcal{M} \cdot \left(1 + \frac{\mathcal{M}}{50.0}\right) & \text{if } \mathcal{M} \cdot \left(1 + \frac{\mathcal{M}}{50.0}\right) \leq 80 \\
        80 & \text{if } \mathcal{M} \cdot \left(1 + \frac{\mathcal{M}}{50.0}\right) > 80.
    \end{cases}
\end{align}
%
The remaining parameter bounds are set to
%
\begin{align}
    0.01 &\ge \eta \ge 0.2499, \\
    -0.9 &\ge s_{1z} \ge 0.9, \\
    -0.9 &\ge s_{2z} \ge 0.9, \\
\end{align}
%
independent of initial event parameters.

Upon creating an instance of the optimiser, a population of candidate solutions is randomly initialised. The first hyperparameter we consider is population size, $N$, determining the number of points in the population. Each point is a 4-dimensional vector, $\textbf{x}_{i}$, given a random value for each parameter inside the bounds, $\textbf{x}_{i} = (\mathcal{M}_{i}, \eta_{i}, s_{1z, i}, s_{2z, i}$), this is our initial population, $\textbf{x}_{N}$.

\subsection{\label{7:sec:original_de}The original SNR optimiser}

The differential evolution optimiser is a stochastic, population-based algorithm that iteratively 'mutates' the population to improve individual SNRs. We can visualise the algorithm as a process similar to natural evolution, where, in each iteration, individuals undergo genetic variation through mutation. This combines features from other individuals to create new trial candidates. Just as nature favours the survival of the fittest, the algorithm evaluates the performance of these trial candidates and retains those that exhibit greater SNR, gradually steering the population towards the optimal solution.

When using differential evolution, we have four key hyperparameters:
%
\begin{itemize}
    \item \textbf{Population size, \( N \)}: Determines how many individuals are in the population.
    \item \textbf{Maximum number of iterations}: Sets how long the algorithm runs, i.e., the maximum number of generations.
    \item \textbf{Mutation factor, \( F \)}: Controls the magnitude of mutation and influences how much individuals are altered by the mutation vectors.
    \item \textbf{Recombination constant, \( R \)}: Also known as the crossover probability, it determines the likelihood that a trial candidate takes parameters from the mutation vector instead of the original individual.
\end{itemize}
%
Another hyperparameter, which we do not tune, is the number of processes that are spawned to run the algorithm in parallel. This is set to ``as many as possible'' when running with PyCBC Live.

The algorithm begins by spawning a population of individuals with initial parameter values within the defined bounds. The network SNR for each individual is calculated, and the individual with the highest SNR, \( \mathbf{x}_{best} \), is identified. Next, a set of mutation vectors are created,
%
\begin{equation}
    \mathbf{v}_i = \mathbf{x}_{best} + F \cdot (\mathbf{x}_{r1} - \mathbf{x}_{r2}),
\end{equation}
%
where \( \mathbf{x}_{r1} \) and \( \mathbf{x}_{r2} \) are distinct random individuals from the population. A trial candidate, \( u_i \), is created by combining the mutation vector \( \mathbf{v}_i \) with the target individual \( \mathbf{x}_i \), according to the rule
%
\begin{equation}
    u_{ij} = 
    \begin{cases} 
    v_{i,j} & \text{if } r_j < R \\ 
    x_{i,j} & \text{otherwise}.
    \end{cases}
\end{equation}
%
Here, \( u_{ij} \) is the \( j \)-th parameter of the trial candidate \( u_i \), \( v_{ij} \) is the \( j \)-th parameter of the mutation vector \( v_i \), and \( x_{ij} \) is the \( j \)-th parameter of the target individual \( x_i \). \( r_j \) is generated uniformly in the interval \([0, 1)\). If \( r_j < R \), the mutation vector value is used; otherwise, the original target individual's value is retained. One exception is that the final parameter (4th) \textbf{always} takes its value from the mutation vector, ensuring that no individual remains completely unchanged in the new population.

Once all trial candidates have been generated, their network SNRs are calculated and compare to the target individual SNR. If a trial candidate has a higher network SNR than the original target individual, it replaces the target. If not, the trial candidate is discarded. The process of creating mutation vectors and generating trial candidates is repeated until the maximum number of iterations is reached, or another stopping criterion is satisfied.

\section{\label{7:sec:additional-improvements}Improvements to the optimiser between observing runs}

The PyCBC programme \texttt{pycbc\_optimize\_snr} has been under irregular but constant development to improve the functionality. There are a number of improvements to the programme which have improved the computing time and maximum SNR found. These have been implemented between the third observing run, when the SNR optimiser was created, and the fourth observing run where the SNR optimiser is currently running on live data. 

\subsection{\label{7:sec:de_hyperparameter_tuning}Tuning hyperparameters}

Tuning the four hyperparameters for the differential evolution optimiser allows for the best performance of the SNR optimiser in the live search. We optimised the following hyperparameters:
%
\begin{itemize}
    \item Population size
    \item Maximum number of iterations
    \item Mutation factor
    \item Recombination factor
\end{itemize}
%
where a balance must be struck between SNR and computing time. To maximise network SNR we would use larger population sizes, more iterations, higher mutation factors and a lower recombination rate, but this will widen the effective search radius and increase the amount of time taken to find an optimised value.

As shown previously, the original values for the hyperparameters were able to recover the $3\%$ missing SNR from any template mismatch therefore, we chose to tune hyperparameters to reduce the time to run the programme. The computing time is directly related to both the population size and maximum number of iterations, which had initial values $N = 200$ and $\texttt{maxiter} = 100$. Using a simple grid search over these two hyperparameters for a number of events, we were able to maintain the SNR recovery while reducing the computing time by ${\sim}25\%$ on average using $N = 100$ and $\texttt{maxiter} = 50$. These were the first set of improvements for the PyCBC Live SNR optimiser.

\subsection{Initial point in the population}

The SNR optimiser can miss the maximum SNR of the parameter space if it is not searched with a fine enough set of particles. Not only can the maximum point be missed, but the maximum can be found below the SNR recovered by the initial PyCBC Live event. To prevent this, we can set a floor on the optimiser SNR by including our initial guess into the initial swarm (or population). Including this initial template into the swarm will set the best position, allowing for a faster convergence on the maximum SNR.

\subsection{Astrophysical spin bounds}

The bounds described in Section~\ref{7:sec:original_bounds} are very general and cover a wide parameters space. The PyCBC Live search is capable of detecting \gwadj signals from binary black hole, binary neutron star and, neutron star — black holes. We assume a physical limit on  neutron star spin~\cite{Harry_Lundgren:2012} therefore we can impose more astrophysically informed spin bounds on objects with masses consistent with neutron stars
%
\begin{align}
    \text{spin bounds} &= 
    \begin{cases} 
        -0.4 - 0.4 & \text{if } \text{max mass} < 3 \, M_{\odot}, \\
        -0.9 - 0.9 & \text{if } \text{max mass} > 3 \, M_{\odot},
    \end{cases} 
\end{align}
%
it is important to impose the condition dependent on the maximum mass the optimiser is allowed to search over. If the optimiser is allowed to assign masses to particles greater than the upper mass limit on neutron stars then we have to let the spin vary by up to the black hole spin bounds because the optimal template could be in this region even if the initial template (from which the bounds are calculated) isn't.

\subsection{Chirp time boundaries}

Another improvement made to the parameter bounds is determining the $\mathcal{M}$ bounds using a constant chirp time window. We define the chirp time as the time between the start of the signal (at some define lower frequency, $f_{L}$) and the peak frequency prior to the merger
%
\begin{equation}
    \tau_0 = A_{0}\left(\mathcal{M}\right)^{-5/3}.
\end{equation}
%
where
%
\begin{equation}
    A_{0} = \frac{5}{256 \left(\pi f_{L}\right)^{8/3}}.
\end{equation}
%
The chirp time to Newtonian order, $\tau_{0}$, depends only on the two masses, $m_{1}$ and $m_{2}$~\cite{Cokelaer:2007}. By using a chirp time window we can search the $\mathcal{M}$ parameter space for signals that look far more physically similar than if we were just changing $\mathcal{M}$ itself.

A higher mass \gwadj event will merge at lower frequencies and therefore have a shorter chirp time. To calculate the $\mathcal{M}$ bounds we first calculate the chirp time of the initial event, then we subtract the constant chirp time window ($2$ seconds in PyCBC Live) and convert back to $\mathcal{M}$ to find the maximum $\mathcal{M}$ bound and add the window and convert to find the minimum $\mathcal{M}$ bound.

We also improve the $\eta$ bounds by imposing a minimum mass of any component object $\text{min}(m) = 0.99$ and calculating the maximum mass of $m_{1}$ using the maximum $\mathcal{M}$. Using this, we can calculate the \textit{minimum} value of $\eta$, again by using the minimum mass of any component and the maximum mass of $m_{1}$. Then using the same maximum $\eta$ previously defined, we are able to define the upper mass bound on $m_{2}$.

These changes to the parameter bound calculation give us the boundaries for $\mathcal{M}$ and $\eta$ as,
%
\begin{align}
    \left(\frac{A_{0}}{\tau_{0} + 2.0}\right)^{\frac{3}{5}} &\ge \mathcal{M} \ge \left(\frac{A_{0}}{\tau_{0} - 2.0}\right)^{\frac{3}{5}}, \\[10pt]
    \frac{\text{max}(m_{1}) \cdot 0.99}{(\text{max}(m_{1}) + 0.99)^{2}} &\ge \eta \ge 0.2499,
\end{align}
%
which allow for less time to be wasted in computing regions of the parameter space which we know will not contain the maximum point.

\section{\label{7:sec:results}O3 optimisation results}

To evaluate the performance of the SNR optimiser in the PyCBC Live search we analyse the events uploaded by the PyCBC Live search to GraceDB. There is a \gwadj mock-data challenge (MDC) that runs continuously to enable live search pipelines to test pipelines and changes to the pipelines prior to enabling them on the real \gwadj data. The MDC replays $40$ days of third observing run \gwadj data with simulated injections continuously, providing a much larger rate of signals to test changes on.

We query GraceDB for all PyCBC `grace events'\footnote{Grace event refers to an individual event uploaded by a pipeline. The initial PyCBC upload and the SNR optimiser upload are separate grace events.} uploaded by the PyCBC full bandwidth MDC search between the dates \texttt{2024-05-30} and \texttt{2024-07-16} and retrieve $10270$ grace events, of which $5091$ were uploaded by the SNR optimiser. Each grace event has an associated `super event' to which multiple pipelines (and multiple grace events from each pipeline) are assigned, of the SNR optimised grace events, $5008$ were assigned a preferred grace event uploaded by PyCBC Live. Finally, of these PyCBC preferred super events, $4600$ had SNR optimised grace events as the preferred events. In $91.85\%$ of cases, when the SNR optimiser has uploaded a grace event, it is preferred over the original PyCBC Live uploaded grace event.

Figure~\ref{7:fig:snr-diffs} shows the change in SNR between original upload and SNR optimised upload for all these SNR optimised events and Figure~\ref{7:fig:latencies} shows the latency between original upload and SNR optimised upload.
%
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/7_snr_optimiser/snr_diffs.pdf}
    \caption{The percentage change in SNR between the optimised SNR and original SNR for GraceDB super events found between \texttt{2024-05-30} and \texttt{2024-07-16} that were found with PyCBC Live and have an SNR optimised grace event in the \gwadj data third observing run replay mock-data challenge.}
    \label{7:fig:snr-diffs}
\end{figure}
%
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/7_snr_optimiser/latencies.pdf}
    \caption{The time after original grace event upload for the SNR optimiser to upload an SNR optimised grace event for GraceDB super events found between \texttt{2024-05-30} and \texttt{2024-07-16} that were found with PyCBC Live and have an SNR optimised grace event in the \gwadj data third observing run replay mock-data challenge.}
    \label{7:fig:latencies}
\end{figure}
%
The average change in SNR optimised events is a $+1.64\%$ increase in SNR. We can see many events which have lost significant amounts of SNR when optimised, these are caused by the bounds of the SNR optimisation parameter space not overlapping with the template bank parameter space or the super event being caused by an exceptional event. As an example, the event with the highest loss in SNR had a negative change in SNR of $-45.67\%$, the original grace event parameters were: $m_{1} = 68.91 \, \text{M}_{\odot}$, $m_{2} = 1.08 \, \text{M}_{\odot}$, $s_{1z} = 0.994$, $s_{2z} = 0.0$, this event is very significantly precessing and has a very large mass ratio making the parameter space difficult to optimise over. Even though the original candidate was within the parameter space, the differential evolution optimiser enforces a mutation at every iteration, so the initial best point can be lost and never recovered with the number of iterations being performed. Complicated parameter spaces are difficult for the optimiser to explore in the number of iterations. When the SNR optimiser uploads a grace event, it will achieve an average increase in SNR of $1.64\%$ with an average latency between uploads of $36.97 \, \text{seconds}$. Figure~\ref{7:fig:mchirp_latency_diff} shows the SNR change in optimised events against the event's chirp mass coloured by the latency, it can be clearly seen that lower chirp mass events have longer optimisation times.
%
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{images/7_snr_optimiser/mchirp_snr_diff.pdf}
    \caption{The percentage change in SNR against the chirp mass for each \gwadj event identified by the MDC search with an SNR optimised event, the injections are coloured by the latency between initial event upload and optimised event upload which is directly related to the time required for the optimiser to run.}
    \label{7:fig:mchirp_latency_diff}
\end{figure}
%

\section{\label{7:sec:exploring_alt_opts}Exploring alternate optimisation algorithms}

After improving the differential evolution optimisation algorithm, we began to investigate other optimisation algorithms that could be used to greater success for the PyCBC Live problem space. The SciPy package has a module dedicated to optimisers, \texttt{SciPy.optimize} which offers $2$ alternative optimisers suitable for this optimisation task: brute force optimisation, which involves performing a grid search over the input parameters; and simplicial homology global optimisation (SHGO), an optimisation technique which divides the parameter space into smaller regions and evaluates points in these regions to identify the most promising areas where the best solution might be found~\cite{shgo:2018}.

We dismiss the brute force optimiser immediately and do not consider the SHGO optimiser due to requirements of the parameter space being smooth or non-noisy that we are unsure are fulfilled~\cite{shgo:2018}. We therefore looked outside SciPy and identified the particle swarm optimisation (PSO) algorithm~\cite{pso:1995} as a candidate for the PyCBC Live SNR optimiser. This algorithm has been used for \gwadj searches as shown by~\cite{pso_search_1:2018} and more recently~\cite{pso_search_2:2023}. This made it a good candidate for optimising network SNR in PyCBC Live.

\subsection{\label{7:sec:pso}Particle Swarm Optimisation}

We can describe the particle swarm optimisation (PSO) algorithm similar to how we previously described the differential evolution algorithm. PSO has the hyperparameters:
%
\begin{itemize}
    \item Number of particles, $N$
    \item Maximum number of iterations, $T$
    \item Inertia weight: weight next iteration velocity based on the previous iteration velocity, $w$
    \item Personal learning rate, $c_{1}$
    \item Social learning rate, $c_{2}$
\end{itemize}
%
the number of particles and maximum number of iterations are identical to the differential evolution hyperparameters. The personal and social learning rates can be considered as acceleration coefficients of the particle.

Once again, we are maximising the network SNR of the PyCBC Live event, adjusting the template parameters ($m_{1}$, $m_{2}$, $s_{1z}$ and $s_{2z}$) to find the optimal values to give the maximum network SNR. PSO will initialise a ``swarm'' of particles, each with a unique combination of template parameters which can be considered the position of the particle in the parameter space, $\mathbf{x}_{i}$, the particle will also be given a random velocity, $\mathbf{v}_{i}$. The network SNR of each particle is calculated and the personal best of every particle is set, $\textbf{p}_{i}$ (as this is the only position the particle has occupied). From the swarm, the global best position is determined, $\textbf{g}$.

Next, we update the velocity of each particle
%
\begin{equation}
    v_{i(t+1)} = w \cdot \mathbf{v}_i(t) + c_1 \cdot r_1 \cdot (\mathbf{p}_i - \mathbf{x}_i(t)) + c_2 \cdot r_2 \cdot (\mathbf{g} - \mathbf{x}_i(t)),
    \label{7:eq:pso_velocity_equation}
\end{equation}
%
where $w$ is the inertial velocity of the particle, $c_{1}$ is the personal learning rate, $c_{2}$ is the social learning rate, $r_{1}$ and $r_{2}$ are random numbers uniformly distributed in $\left[0, 1\right]$, $\textbf{p}_{i}$ is the personal best position of the particle $i$ and $\textbf{g}$ is the global best position of the swarm. We can break Equation~\ref{7:eq:pso_velocity_equation} down into three distinct contributions to the velocity of the particle at iteration $t + 1$: $w \cdot \textbf{v}_{i}(t)$, how much weight is placed on the previous velocity of the particle, adjusted using the inertia weight hyperparameter; $c_{1} \cdot r_{1} \cdot \left(\textbf{p}_{i} - \textbf{x}_{i}(t)\right)$, how strongly the particle pulls toward its personal best, adjusted using the personal learning weight hyperparameter; $c_{2} \cdot r_{2} \cdot \left(\textbf{g} - \textbf{x}_{i}(t)\right)$, how strongly the particle pulls toward the global best, adjusted using the social learning weight hyperparameter.

After the velocity of each particle is calculated, the particle positions are updated
%
\begin{equation}
    \mathbf{x}_i(t+1) = \mathbf{x}_i(t) + \mathbf{v}_i(t+1),
\end{equation}
%
and the network SNR of each particle is calculated again. The particle personal bests and the global best are re-evaluated and updated if they have changed, and the iterative process repeats. Upon reaching the number of iterations or if there is convergence in the network SNR value, the algorithm is stopped and the optimal template parameter values are returned which maximise the network SNR.

\subsection{\label{7:sec:tuning-pso}Tuning and evaluating the PSO optimiser}

The PSO optimiser has not been used in the PyCBC Live search on either the MDC or real data, but we have implemented it into PyCBC Live to allow the possibility of it being used in the future. We have tested PSO on the Chapter~\ref{chapter:6-earlywarning} injection set (described in Table~\ref{6:tab:ew_inj_params}) which focuses on the low-mass parameter space, the region which the optimiser has struggled to search over.

Using \texttt{optuna}~\cite{optuna:2019}, a hyperparameter tuner, we tune the five hyperparameters of the PSO optimiser to achieve the greatest SNR for a single \gwadj injection from the injection set. We get rounded hyperparameter values: $\text{iterations} = 50$, $\text{particles} = 150$, $\text{inertia weight} = 0.2$, $\text{personal learning rate} = 0.75$, $\text{social learning rate} = 1.0$. Using these hyperparameter values we search through $21,600 \, \text{seconds}$ of \gwadj data containing \gwadj injections every ${\sim}100 \, \text{seconds}$, with both the current differential evolution optimiser and the PSO optimiser. The differential evolution optimiser achieves an average percent increase in SNR of $0.512 \%$ in an average time of $30.489 \, \text{seconds}$ whereas the PSO optimiser achieves an average increase in SNR of $0.543\%$ in an average time of $32.058 \, \text{seconds}$. The PSO optimiser achieves a greater average SNR increase with a slightly longer average optimisation time. We perform the same test and cut the number of iterations to $25$, leading to an average optimisation time of  $14.638 \, \text{seconds}$ while maintaining an average SNR increase of $0.543\%$.

These tests indicate that the PSO optimiser has the potential to replace the differential evolution optimiser in PyCBC Live and with greater hyperparameter tuning we can produce an SNR optimiser which explores the low-mass parameter space effectively.

\section{\label{7:sec:conclusion}Conclusion and future improvements}
% Limitations: Discuss any limitations of the current optimiser (e.g., computational bottlenecks, situations where the optimisation struggles).
% Broader Impact: How does this optimisation contribute to the broader field of gravitational wave detection?
% Future Work: Mention potential improvements or future research directions that could enhance the SNR optimisation process further.

The SNR optimiser will increase the SNR obtained by the PyCBC Live search pipeline for a \gwadj event in the vast majority of cases, with an average $1.64\%$ increase. This will lead to more accurate sky maps and improved parameter estimation for the \gwadj events. However, as identified by Figure~\ref{7:fig:snr-diffs}, we have a large number of events ($8.15\%$) where the SNR optimiser has \textbf{not} increased the found SNR. We have identified that this is true when the parameter space is more complex, in the case of signals with high mass ratio, non-aligned spins or long duration templates. We have a latency requirement on our optimiser and so are unable to necessarily allow the deep exploration of these parameter spaces.

% Summary: Recap the importance of the SNR optimiser and its role in improving gravitational wave detection.
% Final Thoughts: Reflect on the significance of this work in the context of the PyCBC pipeline and real-time gravitational wave detection efforts.

We have identified the particle swarm optimisation algorithm as a candidate for further investigation to improve the PyCBC Live SNR optimiser and we have shown that hyperparameter tuning can lead to improvements in optimised SNR as well as decrease optimisation time therefore requiring further investigation into hyperparameter tuning to improve both the current and future SNR optimiser configurations.

The implementation of the SNR optimiser in PyCBC Live has improved the prospects of \gwadj detection in low-latency and will enable higher quality science in the post-detection regime. Providing more accurate sky maps for low-latency events will allow better multi-messenger follow-up of these events. The SNR optimiser has many areas of potential improvement that if more time were available, we would seek to investigate and implement. In this subsection, I will discuss some of the improvements that could be made to the SNR optimiser.

\subsubsection{Template bank initial population positions}

The two optimisers that are currently implemented---differential evolution and particle swarm optimisation---rely on spawning an initial random population of points to explore the template parameter space. We have prior knowledge about the parameter space from our templates bank and can place this initial population of points at the points of our template bank, the points will be drawn toward the best matching point from the template bank and hopefully explore the area between template bank points more deeply. If the parameter space bounds are large for an event this will place the population approximately at the correct density for the parameter space as defined by the stochastic template bank placement algorithm (described in Section~\ref{2:sec:template-bank}), more densely covered areas of the template bank will be assigned more initial points to explore that space.

\subsubsection{Template dependent optimisers and hyperparameters}

We have adjusted the parameter space bounds according to the initial template parameters, the mass bounds are dependent on the template chirp time and the spin bounds are dependent on the component object (black hole or neutron star). We could apply further options to both optimisers and the hyperparameters of the optimisers, depending on the template. If high-mass BBH signals require fewer iterations we can adjust that hyperparameter, if low-mass signals require a finer exploration of the parameter space we can change the mutation factor and recombination factor or the inertia and learning rates. We might be able to find optimisers that respond better to specific regions of the parameter space, similar to how the template banks are composed using different techniques for different regions.

\subsubsection{Machine learning optimisers and hyperparameter tuning}

Since starting this PhD in 2020 the rise of machine learning has been relentless, techniques that were considered novel and cutting-edge have fallen by the wayside and newer, more efficient and effective techniques have replaced them. The SNR optimiser can benefit heavily from this catalogue of machine learning based events that could be highly optimised for an SNR optimisation problem. We have a large number of historical events to train such a model on to allow enhanced parameter space exploration, which can allow either a faster optimisation or a deeper optimisation, especially for low-mass signals.

Another area in which machine learning can help is with hyperparameter tuning. Optimising the SNR optimiser hyperparameters will return instant reward for the current configuration of the optimiser, the hyperparameters chosen initially or after our initial optimisation may not still be the correct choice in the fourth observing run and in the future. We generate a template bank for each observing run so we should optimise the hyperparameters too.
